# Streaming Video Model

> **Streaming Video Model** <br>
> Yucheng Zhao, Chong Luo, Chuanxin Tang, Dongdong Chen, Noel Codella, Zheng-Jun Zha <br>
> *CVPR 2023* <br>

[[Paper (Coming soon) ](https://github.com/yuzhms/Streaming-Video-Model)] 
[[arXiv (Coming soon) ](https://github.com/yuzhms/Streaming-Video-Model)] 


## Description   

**Streaming video model** is a general video model, which is applicable to general video understanding tasks. Traditionally, video understanding tasks have been modeled by two separate architectures, specially tailored for two distinct tasks. Streaming video model is the first deep learning architecture that unifies video understanding tasks. We build an instance of streaming video model, namely the streaming video Transformer (S-ViT).S-ViT first produces frame-level features with a memory-enabled temporally-aware spatial encoder to serve the frame-based video tasks. Then the
frame features are input into a task-related temporal decoder to obtain spatiotemporal features for sequence-based tasks. The efficiency and efficacy of S-ViT is demonstrated by the state-of-the-art accuracy in the sequence-based action recognition task and the competitive advantage over conventional architecture in the frame-based MOT task. 

## Update (To Do):

<!-- :white_check_mark: Update SNGAN   -->
:black_square_button: Code Release

:black_square_button: Model Release

We are cleaning and merging the code and hope to release it very soon.



## BibTeX

```bibtex
@inproceedings{zhao2023svm,
  title   = {Streaming Video Model},
  author  = {Yucheng Zhao, Chong Luo, Chuanxin Tang, Dongdong Chen, Noel Codella, Zheng-Jun Zha},
  booktitle = {CVPR},
  year    = {2023}
}
```

  
